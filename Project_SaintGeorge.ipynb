{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Saint George Classifier\n",
    "Задача заключается в том, чтобы сделать классификатор наличия святого Георгия на изображении.\n",
    "\n",
    ">### Dataset\n",
    ">  Датасет, используемый в проекте, состоит из 5700 изображений, из которых 2360 изображений содержат Святого Георгия и 3340 - нет. Весь датасет разделен на 3 части: **70%** данных используется для обучения модели, **20%** для валидации и **10%** для финального тестирования. Причем в каждой из частей соотношение классов 40%-60%, поскольку изначальный датасет не сбалансирован. \n",
    "\n",
    "\n",
    ">### Используемая модель решения\n",
    "> - Так как используемый датасет не велик и отсутствуют большие вычислительные мощности для обучения, построение модели с нуля навряд ли привело бы к классификатору с хорошей точностью. Более усовершенствованный подход (**Transfer learning**)   заключается  в использовании нейронной сети, предварительно обученной на большом наборе данных. В такой сети уже изучены функции, которые полезны для большинства проблем компьютерного зрения, и использование таких функций позволяет достичь большей точности, чем любой другой метод, который полагался бы только на доступные данные. \n",
    ">\n",
    "> В проекте использовалась [Xception](https://keras.io/api/applications/) структура, предобученная на ImageNet dataset. Это относительно небольшая по размерам сеть имеет около 23М параметров и весит 88 Мб, при этом точность классификации на ImageNet составляет 79%. В сравнении, InceptionResNetV2, которая чуть лучше Xception, использует почти 56М параметров и весит 215Мб.\n",
    ">\n",
    "> Обучение данной модели происходит следующим образом\n",
    ">\n",
    ">1. Загрузим веса с ImageNet в Xception, из которой убраны верхние полносвязные слои, поскольку эти слои содержат в себе веса подходящие для классификации изображений в наборе данных ImageNet. Далее мы замораживаем все слои обрезанной Xception, после чего к данной модели добавляем два собственных, нетренированных, полносвязных слоя (последний слой это сигмойд) и производим обучение. После данной процедуры точность на training set  cоставляет **79%**, а  на validation достигает **80%**.\n",
    ">2.  Чтобы ещё больше улучшить данный результат мы производим так называемый **Fine-tuning** верхних слоёв предобученной Xception. Для этого мы загружаем обученную на этапе 1 модель и размораживаем последние два блока Xception и повторно обучаем.  При этом используем в качестве алгоритма оптимизации SGD с низким  коэффициентом скорости обучения, чтобы не разрушить ранее полученный результат. Дообученная модель достигает точности в **89%** на training set и **84%** на validation.\n",
    ">\n",
    "> Проверив модель на данных, которых она никогда не видела (test dataset) и которые не использовались для настройки гиперпараметров, увидим точность **83%**. Данный результат можно улучшить путем увелечения времени обучения модели на 1 этапе. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, optimizers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=150\n",
    "Image_Height=150\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "batch_siz = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_georges = \"D:\\\\Project_Georges\\\\georges\"\n",
    "filenames_georges = list(map(lambda x: path_georges + \"\\\\\" + x, os.listdir(path_georges) )) \n",
    "dictn_georges = { 'filename':filenames_georges, \"class\":np.ones(len(filenames_georges), dtype=int) }\n",
    "df_1 = pd.DataFrame(dictn_georges)\n",
    "df_1['class'] = df_1['class'].apply(lambda x: 'georges')\n",
    "\n",
    "path_non_georges = \"D:\\\\Project_Georges\\\\non_georges\"\n",
    "filenames_non_georges = list(map(lambda x: path_non_georges +\"\\\\\" + x, os.listdir(path_non_georges) )) \n",
    "dictn_non_georges = { 'filename':filenames_non_georges, \"class\":np.zeros(len(filenames_non_georges), dtype=int) }\n",
    "df_0 = pd.DataFrame(dictn_non_georges)\n",
    "df_0['class'] = df_0['class'].apply(lambda x: 'non_georges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2360, 3340)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_1), len(df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем наш датасет на training, validation, and test в соотношении 70%-20%-10%. Соотношение классов в каждом наборе 40%-60%.\n",
    "alpha = np.round(len(df_0) / len(df_1) , 2 )\n",
    "\n",
    "frac_1 = int(0.7*len(df_1))\n",
    "frac_0 = int(0.7*alpha*len(df_1))\n",
    "\n",
    "frac_1_val = int(0.9*len(df_1))\n",
    "frac_0_val = int(0.9*alpha*len(df_1))\n",
    "\n",
    "df_1 = df_1.sample(frac=1).reset_index(drop=True)\n",
    "df_0 = df_0.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_train = pd.concat([df_1.loc[ : frac_1-1 ], df_0.loc[ :frac_0 -1 ] ], axis=0)\n",
    "\n",
    "df_val =  pd.concat([df_1.loc[ frac_1 : frac_1_val-1 ], df_0.loc[frac_0 :frac_0_val -1 ] ], axis=0)\n",
    "\n",
    "df_test = pd.concat([df_1.loc[frac_1_val : ], df_0.loc[frac_0_val : ]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_val = df_val.sample(frac=1).reset_index(drop=True)\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3997 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  rotation_range=15,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(df_train,\n",
    "                                                    x_col =\"filename\",\n",
    "                                                    y_col=\"class\",\n",
    "                                                   target_size=Image_Size,\n",
    "                                                   batch_size=batch_siz,\n",
    "                                                   class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1143 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(df_val,\n",
    "                                                              x_col =\"filename\",\n",
    "                                                              y_col=\"class\",\n",
    "                                                              target_size=Image_Size,\n",
    "                                                              batch_size=batch_siz,\n",
    "                                                              class_mode='binary',\n",
    "                                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 560 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(df_test,\n",
    "                                                  x_col =\"filename\",\n",
    "                                                  y_col=\"class\",\n",
    "                                                  target_size=Image_Size,\n",
    "                                                  batch_size=batch_siz,\n",
    "                                                  class_mode='binary',\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем Xception модель (веса) за исключением верхних выходных слоёв\n",
    "base_xcpt = Xception(include_top=False, weights = 'imagenet', pooling='avg', input_shape = (Image_Width,Image_Height,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добовляем наши верхние слои к Xception\n",
    "def new_top_layers(base):\n",
    "    x = base.output\n",
    "    x = Dense(512 , activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    pred = Dense(1, activation= 'sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs= base.input, outputs= pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем нашу модель, причем все веса основы (Xception) заморожены\n",
    "def assemble_model(model, base):\n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer= 'rmsprop', loss= 'binary_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = new_top_layers(base_xcpt)\n",
    "assemble_model(model, base_xcpt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 36, 36, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 18, 18, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 18, 18, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 728)    186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 9, 9, 728)    2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 5, 5, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 5, 5, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,911,081\n",
      "Trainable params: 1,049,601\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Инициализируем EarlyStopping и сохраняем (после model.fit) лучшую модель на диск\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=11)\n",
    "checkpointer = ModelCheckpoint(filepath=\"D:\\\\Project_Georges\\\\top_weights.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.7004 - accuracy: 0.6441 \n",
      "Epoch 00001: val_loss improved from inf to 0.52924, saving model to D:\\Project_Georges\\top_weights.hdf5\n",
      "125/125 [==============================] - 844s 7s/step - loss: 0.7013 - accuracy: 0.6442 - val_loss: 0.5292 - val_accuracy: 0.7384\n",
      "Epoch 2/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.6077 - accuracy: 0.6991 \n",
      "Epoch 00002: val_loss did not improve from 0.52924\n",
      "125/125 [==============================] - 827s 7s/step - loss: 0.6080 - accuracy: 0.6988 - val_loss: 0.5548 - val_accuracy: 0.7533\n",
      "Epoch 3/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.5699 - accuracy: 0.7203 \n",
      "Epoch 00003: val_loss did not improve from 0.52924\n",
      "125/125 [==============================] - 834s 7s/step - loss: 0.5677 - accuracy: 0.7215 - val_loss: 0.5620 - val_accuracy: 0.7577\n",
      "Epoch 4/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.5418 - accuracy: 0.7400 \n",
      "Epoch 00004: val_loss did not improve from 0.52924\n",
      "125/125 [==============================] - 833s 7s/step - loss: 0.5416 - accuracy: 0.7406 - val_loss: 0.5810 - val_accuracy: 0.7594\n",
      "Epoch 5/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.5338 - accuracy: 0.7410 \n",
      "Epoch 00005: val_loss did not improve from 0.52924\n",
      "125/125 [==============================] - 835s 7s/step - loss: 0.5328 - accuracy: 0.7413 - val_loss: 0.7337 - val_accuracy: 0.7209\n",
      "Epoch 6/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4977 - accuracy: 0.7611 \n",
      "Epoch 00006: val_loss did not improve from 0.52924\n",
      "125/125 [==============================] - 823s 7s/step - loss: 0.4975 - accuracy: 0.7613 - val_loss: 0.7130 - val_accuracy: 0.7122\n",
      "Epoch 7/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4884 - accuracy: 0.7687 \n",
      "Epoch 00007: val_loss did not improve from 0.52924\n",
      "125/125 [==============================] - 816s 7s/step - loss: 0.4876 - accuracy: 0.7696 - val_loss: 0.5838 - val_accuracy: 0.7638\n",
      "Epoch 8/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4831 - accuracy: 0.7735 \n",
      "Epoch 00008: val_loss did not improve from 0.52924\n",
      "125/125 [==============================] - 819s 7s/step - loss: 0.4826 - accuracy: 0.7736 - val_loss: 0.7432 - val_accuracy: 0.7227\n",
      "Epoch 9/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4587 - accuracy: 0.7934 \n",
      "Epoch 00009: val_loss improved from 0.52924 to 0.51925, saving model to D:\\Project_Georges\\top_weights.hdf5\n",
      "125/125 [==============================] - 820s 7s/step - loss: 0.4598 - accuracy: 0.7921 - val_loss: 0.5193 - val_accuracy: 0.8005\n",
      "Epoch 10/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4541 - accuracy: 0.7894 \n",
      "Epoch 00010: val_loss did not improve from 0.51925\n",
      "125/125 [==============================] - 839s 7s/step - loss: 0.4533 - accuracy: 0.7896 - val_loss: 0.5741 - val_accuracy: 0.7795\n",
      "Epoch 11/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4584 - accuracy: 0.7897 \n",
      "Epoch 00011: val_loss did not improve from 0.51925\n",
      "125/125 [==============================] - 832s 7s/step - loss: 0.4583 - accuracy: 0.7891 - val_loss: 0.6292 - val_accuracy: 0.7594\n",
      "Epoch 12/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4310 - accuracy: 0.8081 \n",
      "Epoch 00012: val_loss did not improve from 0.51925\n",
      "125/125 [==============================] - 846s 7s/step - loss: 0.4302 - accuracy: 0.8084 - val_loss: 0.5325 - val_accuracy: 0.7970\n",
      "Epoch 13/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4386 - accuracy: 0.8033 \n",
      "Epoch 00013: val_loss did not improve from 0.51925\n",
      "125/125 [==============================] - 849s 7s/step - loss: 0.4383 - accuracy: 0.8034 - val_loss: 0.6100 - val_accuracy: 0.7900\n",
      "Epoch 14/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4217 - accuracy: 0.8101 \n",
      "Epoch 00014: val_loss did not improve from 0.51925\n",
      "125/125 [==============================] - 838s 7s/step - loss: 0.4215 - accuracy: 0.8104 - val_loss: 0.6197 - val_accuracy: 0.7848\n",
      "Epoch 15/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4175 - accuracy: 0.8159 \n",
      "Epoch 00015: val_loss did not improve from 0.51925\n",
      "125/125 [==============================] - 814s 7s/step - loss: 0.4169 - accuracy: 0.8164 - val_loss: 0.5547 - val_accuracy: 0.7918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e6a5603940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=15, steps_per_epoch= np.ceil(train_generator.samples/ train_generator.batch_size), \n",
    "         validation_data=validation_generator, validation_steps=np.ceil(validation_generator.samples/ validation_generator.batch_size),\n",
    "         callbacks=[early_stop, checkpointer],\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e6823db5c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем лучшую модель\n",
    "model = load_model(\"D:\\\\Project_Georges\\\\top_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001D72EC46A20> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72EC46F60> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72EC99710> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72EC99A90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72EC99C18> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECD00F0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECD0470> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECD05F8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECD0C88> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECD7048> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECD71D0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECD7860> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72ECD7BE0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001D72ECDC0F0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECDC358> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ECDC6D8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECDC828> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECDC9B0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECE3080> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECE3400> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECE3588> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECE3C18> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72ECE3F98> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001D72ECE64A8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECE6710> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ECE6A90> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECE6BE0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECE6D68> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECEF438> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECEF7B8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECEF940> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECEFFD0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72ECF1390> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001D72ECF1860> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECF1AC8> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ECF1E48> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECF1F98> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECF9160> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECF97F0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECF9B70> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECF9CF8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED003C8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED00748> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED008D0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED00F60> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED01320> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED01470> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED015F8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED01C88> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED08048> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED081D0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED08860> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED08BE0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED08D68> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED0F438> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED0F7B8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED0F908> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED0FA90> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED15160> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED154E0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED15668> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED15CF8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED1B0B8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED1B240> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED1B8D0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED1BC50> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED1BDA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED1BF28> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED215F8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED21978> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED21B00> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED281D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED28550> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED286D8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED28D68> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED2B128> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED2B278> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED2B400> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED2BA90> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED2BE10> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED2BF98> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED32668> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED329E8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED32B70> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED37240> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED375C0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED37710> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED37898> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED37F28> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED3D2E8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED3D470> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED3DB00> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED3DE80> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED3E048> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED3E6D8> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED3EA58> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED3EBA8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED3ED30> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED4B400> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED4B780> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED4B908> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED4BF98> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED4E358> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED4E4E0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED4EB70> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED4EEF0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED55080> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED55208> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED55898> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED55C18> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED55DA0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED5A470> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED5A7F0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED5A978> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED5D048> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED5D3C8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED5D518> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED5D6A0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED5DD30> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED650F0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED65278> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED65908> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72ED65C88> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001D72ED68198> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED68400> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED68780> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED688D0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED68F98> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED71358> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED714E0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED71B70> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED71EF0> False\n",
      "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x000001D72ED770B8> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001D72ED771D0> True\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x000001D72ED774E0> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001D72ED77630> True\n"
     ]
    }
   ],
   "source": [
    "# Проверяем какие слои заморожены\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, которая размораживает верхние num_trainable слои\n",
    "def finetune(model, num_trainable):\n",
    "    for layer in model.layers[ : len(model.layers) - num_trainable]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[len(model.layers) - num_trainable : ]: \n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizers.SGD(lr=0.001, momentum=0.9),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размораживаем верхние 2 блока (блок 13 и 14) Xception (19 слоёв)\n",
    "finetune(model, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000001D72EC46A20> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72EC46F60> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72EC99710> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72EC99A90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72EC99C18> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECD00F0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECD0470> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECD05F8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECD0C88> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECD7048> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECD71D0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECD7860> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72ECD7BE0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001D72ECDC0F0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECDC358> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ECDC6D8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECDC828> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECDC9B0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECE3080> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECE3400> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECE3588> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECE3C18> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72ECE3F98> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001D72ECE64A8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECE6710> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ECE6A90> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECE6BE0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECE6D68> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECEF438> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECEF7B8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECEF940> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECEFFD0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72ECF1390> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001D72ECF1860> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECF1AC8> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ECF1E48> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECF1F98> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECF9160> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ECF97F0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ECF9B70> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ECF9CF8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED003C8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED00748> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED008D0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED00F60> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED01320> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED01470> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED015F8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED01C88> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED08048> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED081D0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED08860> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED08BE0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED08D68> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED0F438> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED0F7B8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED0F908> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED0FA90> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED15160> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED154E0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED15668> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED15CF8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED1B0B8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED1B240> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED1B8D0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED1BC50> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED1BDA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED1BF28> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED215F8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED21978> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED21B00> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED281D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED28550> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED286D8> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED28D68> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED2B128> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED2B278> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED2B400> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED2BA90> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED2BE10> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED2BF98> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED32668> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED329E8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED32B70> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED37240> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED375C0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED37710> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED37898> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED37F28> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED3D2E8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED3D470> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED3DB00> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED3DE80> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED3E048> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED3E6D8> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED3EA58> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED3EBA8> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED3ED30> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED4B400> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED4B780> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED4B908> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED4BF98> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED4E358> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED4E4E0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED4EB70> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED4EEF0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED55080> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED55208> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED55898> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED55C18> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED55DA0> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED5A470> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED5A7F0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED5A978> False\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED5D048> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED5D3C8> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED5D518> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED5D6A0> True\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED5DD30> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED650F0> True\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED65278> True\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED65908> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001D72ED65C88> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001D72ED68198> True\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED68400> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001D72ED68780> True\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED688D0> True\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED68F98> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED71358> True\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001D72ED714E0> True\n",
      "<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x000001D72ED71B70> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001D72ED71EF0> True\n",
      "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x000001D72ED770B8> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001D72ED771D0> True\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x000001D72ED774E0> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001D72ED77630> True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer_1 = ModelCheckpoint(filepath='D:\\\\Project_Georges\\\\finetune_model.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.4311 - accuracy: 0.8020 \n",
      "Epoch 00001: val_loss improved from inf to 0.44357, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "125/125 [==============================] - 817s 7s/step - loss: 0.4304 - accuracy: 0.8021 - val_loss: 0.4436 - val_accuracy: 0.8154\n",
      "Epoch 2/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.3889 - accuracy: 0.8166 \n",
      "Epoch 00002: val_loss improved from 0.44357 to 0.43968, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "125/125 [==============================] - 809s 6s/step - loss: 0.3884 - accuracy: 0.8169 - val_loss: 0.4397 - val_accuracy: 0.8171\n",
      "Epoch 3/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.3797 - accuracy: 0.8265 \n",
      "Epoch 00003: val_loss did not improve from 0.43968\n",
      "125/125 [==============================] - 808s 6s/step - loss: 0.3793 - accuracy: 0.8264 - val_loss: 0.4401 - val_accuracy: 0.8128\n",
      "Epoch 4/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.3691 - accuracy: 0.8363 \n",
      "Epoch 00004: val_loss improved from 0.43968 to 0.43287, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "125/125 [==============================] - 810s 6s/step - loss: 0.3682 - accuracy: 0.8369 - val_loss: 0.4329 - val_accuracy: 0.8206\n",
      "Epoch 5/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.3371 - accuracy: 0.8520 \n",
      "Epoch 00005: val_loss did not improve from 0.43287\n",
      "125/125 [==============================] - 806s 6s/step - loss: 0.3379 - accuracy: 0.8516 - val_loss: 0.4337 - val_accuracy: 0.8268\n",
      "Epoch 6/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.3359 - accuracy: 0.8492 \n",
      "Epoch 00006: val_loss did not improve from 0.43287\n",
      "125/125 [==============================] - 808s 6s/step - loss: 0.3352 - accuracy: 0.8496 - val_loss: 0.4343 - val_accuracy: 0.8294\n",
      "Epoch 7/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.3165 - accuracy: 0.8620 \n",
      "Epoch 00007: val_loss improved from 0.43287 to 0.42859, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "125/125 [==============================] - 811s 6s/step - loss: 0.3161 - accuracy: 0.8621 - val_loss: 0.4286 - val_accuracy: 0.8329\n",
      "Epoch 8/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.3179 - accuracy: 0.8638 \n",
      "Epoch 00008: val_loss did not improve from 0.42859\n",
      "125/125 [==============================] - 808s 6s/step - loss: 0.3168 - accuracy: 0.8644 - val_loss: 0.4951 - val_accuracy: 0.8075\n",
      "Epoch 9/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.3013 - accuracy: 0.8673 \n",
      "Epoch 00009: val_loss did not improve from 0.42859\n",
      "125/125 [==============================] - 808s 6s/step - loss: 0.3021 - accuracy: 0.8672 - val_loss: 0.4348 - val_accuracy: 0.8320\n",
      "Epoch 10/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.2803 - accuracy: 0.8784 \n",
      "Epoch 00010: val_loss did not improve from 0.42859\n",
      "125/125 [==============================] - 809s 6s/step - loss: 0.2796 - accuracy: 0.8787 - val_loss: 0.4403 - val_accuracy: 0.8311\n",
      "Epoch 11/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.2686 - accuracy: 0.8858 \n",
      "Epoch 00011: val_loss improved from 0.42859 to 0.42746, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "125/125 [==============================] - 811s 6s/step - loss: 0.2684 - accuracy: 0.8857 - val_loss: 0.4275 - val_accuracy: 0.8408\n",
      "Epoch 12/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.2759 - accuracy: 0.8865 \n",
      "Epoch 00012: val_loss did not improve from 0.42746\n",
      "125/125 [==============================] - 808s 6s/step - loss: 0.2752 - accuracy: 0.8869 - val_loss: 0.4315 - val_accuracy: 0.8390\n",
      "Epoch 13/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.2561 - accuracy: 0.8931 \n",
      "Epoch 00013: val_loss improved from 0.42746 to 0.41998, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "125/125 [==============================] - 811s 6s/step - loss: 0.2554 - accuracy: 0.8934 - val_loss: 0.4200 - val_accuracy: 0.8434\n",
      "Epoch 14/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.2621 - accuracy: 0.8918 \n",
      "Epoch 00014: val_loss did not improve from 0.41998\n",
      "125/125 [==============================] - 809s 6s/step - loss: 0.2616 - accuracy: 0.8917 - val_loss: 0.4464 - val_accuracy: 0.8364\n",
      "Epoch 15/15\n",
      "124/125 [============================>.] - ETA: 6s - loss: 0.2353 - accuracy: 0.9057 \n",
      "Epoch 00015: val_loss did not improve from 0.41998\n",
      "125/125 [==============================] - 810s 6s/step - loss: 0.2349 - accuracy: 0.9059 - val_loss: 0.4403 - val_accuracy: 0.8416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d72cf535c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Повторно обучаем нашу модель с двумя размороженными блоками (13 и 14)\n",
    "model.fit_generator(train_generator, epochs=15, steps_per_epoch= np.ceil(train_generator.samples/ train_generator.batch_size), \n",
    "         validation_data=validation_generator, validation_steps=np.ceil(validation_generator.samples/ validation_generator.batch_size),\n",
    "         callbacks=[early_stop, checkpointer_1],\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41998096120854217, 0.8433946]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(\"D:\\\\Project_Georges\\\\finetune_model.hdf5\")\n",
    "model.evaluate_generator(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions (test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       236\n",
      "           1       0.83      0.88      0.86       324\n",
      "\n",
      "    accuracy                           0.83       560\n",
      "   macro avg       0.83      0.82      0.82       560\n",
      "weighted avg       0.83      0.83      0.83       560\n",
      "\n",
      "[[179  57]\n",
      " [ 39 285]]\n",
      "{'georges': 0, 'non_georges': 1}\n"
     ]
    }
   ],
   "source": [
    "results = model.predict_generator(test_generator, steps=np.ceil(test_generator.samples/ test_generator.batch_size))\n",
    "print(classification_report(test_generator.classes, np.round(results[:,0])))\n",
    "print(confusion_matrix(y_true= test_generator.classes, y_pred= np.round(results[:,0])))\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
