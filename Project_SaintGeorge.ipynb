{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Saint George Classifier\n",
    "Задача заключается в том, чтобы сделать классификатор наличия святого Георгия на изображении.\n",
    "\n",
    ">### Dataset\n",
    ">  Датасет, используемый в проекте, состоит из 5700 изображений, из которых 2360 изображений содержат Святого Георгия и 3340 - нет. Весь датасет разделен на 3 части: **70%** данных используется для обучения модели, **20%** для валидации и **10%** для финального тестирования. Причем в каждой из частей соотношение классов 40%-60%, поскольку изначальный датасет не сбалансирован. \n",
    "\n",
    "\n",
    ">### Используемая модель решения\n",
    "> - Так как используемый датасет не велик и отсутствуют большие вычислительные мощности для обучения, построение модели с нуля навряд ли привело бы к классификатору с хорошей точностью. Более усовершенствованный подход (**Transfer learning**)   заключается  в использовании нейронной сети, предварительно обученной на большом наборе данных. В такой сети уже изучены функции, которые полезны для большинства проблем компьютерного зрения, и использование таких функций позволяет достичь большей точности, чем любой другой метод, который полагался бы только на доступные данные. \n",
    ">\n",
    "> В проекте использовалась [Xception](https://keras.io/api/applications/) структура, предобученная на ImageNet dataset. Это относительно небольшая по размерам сеть имеет около 23М параметров и весит 88 Мб, при этом точность классификации на ImageNet составляет 79%. В сравнении, InceptionResNetV2, которая чуть лучше Xception, использует почти 56М параметров и весит 215Мб.\n",
    ">\n",
    "> Обучение данной модели происходит следующим образом\n",
    ">\n",
    ">1. Загрузим веса с ImageNet в Xception, из которой убраны верхние полносвязные слои, поскольку эти слои содержат в себе веса подходящие для классификации изображений в наборе данных ImageNet. Далее мы замораживаем все слои обрезанной Xception, после чего к данной модели добавляем два собственных, нетренированных, полносвязных слоя (последний слой это сигмойд) и производим обучение. После данной процедуры точность на training set  cоставляет **85%**, а  на validation достигает **83%**.\n",
    ">2.  Чтобы ещё больше улучшить данный результат мы производим так называемый **Fine-tuning** верхних слоёв предобученной Xception. Для этого мы загружаем обученную на этапе 1 модель и размораживаем последние два блока Xception и повторно обучаем.  При этом используем в качестве алгоритма оптимизации SGD с низким  коэффициентом скорости обучения, чтобы не разрушить ранее полученный результат. Дообученная модель достигает точности в **95%** на training set и **90%** на validation.\n",
    ">\n",
    "> Проверив модель на данных, которых она никогда не видела (test dataset) и которые не использовались для настройки гиперпараметров, увидим точность **90%**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, optimizers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from tensorflow.keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 2GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data pre-processing and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=150\n",
    "Image_Height=150\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "batch_siz = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_georges = \"D:\\\\Project_Georges\\\\georges\"\n",
    "filenames_georges = list(map(lambda x: path_georges + \"\\\\\" + x, os.listdir(path_georges) )) \n",
    "dictn_georges = { 'filename':filenames_georges, \"class\":np.ones(len(filenames_georges), dtype=int) }\n",
    "df_1 = pd.DataFrame(dictn_georges)\n",
    "df_1['class'] = df_1['class'].apply(lambda x: 'georges')\n",
    "\n",
    "path_non_georges = \"D:\\\\Project_Georges\\\\non_georges\"\n",
    "filenames_non_georges = list(map(lambda x: path_non_georges +\"\\\\\" + x, os.listdir(path_non_georges) )) \n",
    "dictn_non_georges = { 'filename':filenames_non_georges, \"class\":np.zeros(len(filenames_non_georges), dtype=int) }\n",
    "df_0 = pd.DataFrame(dictn_non_georges)\n",
    "df_0['class'] = df_0['class'].apply(lambda x: 'non_georges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2360, 3340)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_1), len(df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем наш датасет на training, validation, and test в соотношении 70%-20%-10%. Соотношение классов в каждом наборе 40%-60%.\n",
    "alpha = np.round(len(df_0) / len(df_1) , 2 )\n",
    "\n",
    "frac_1 = int(0.7*len(df_1))\n",
    "frac_0 = int(0.7*alpha*len(df_1))\n",
    "\n",
    "frac_1_val = int(0.9*len(df_1))\n",
    "frac_0_val = int(0.9*alpha*len(df_1))\n",
    "\n",
    "df_1 = df_1.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df_0 = df_0.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_train = pd.concat([df_1.loc[ : frac_1-1 ], df_0.loc[ :frac_0 -1 ] ], axis=0)\n",
    "\n",
    "df_val =  pd.concat([df_1.loc[ frac_1 : frac_1_val-1 ], df_0.loc[frac_0 :frac_0_val -1 ] ], axis=0)\n",
    "\n",
    "df_test = pd.concat([df_1.loc[frac_1_val : ], df_0.loc[frac_0_val : ]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df_val = df_val.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df_test = df_test.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3997 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.1,\n",
    "                                  rotation_range=15,\n",
    "                                  zoom_range=0.2,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(df_train,\n",
    "                                                    x_col =\"filename\",\n",
    "                                                    y_col=\"class\",\n",
    "                                                   target_size=Image_Size,\n",
    "                                                   batch_size=batch_siz,\n",
    "                                                   class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1143 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(df_val,\n",
    "                                                              x_col =\"filename\",\n",
    "                                                              y_col=\"class\",\n",
    "                                                              target_size=Image_Size,\n",
    "                                                              batch_size=batch_siz,\n",
    "                                                              class_mode='binary',\n",
    "                                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 560 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(df_test,\n",
    "                                                  x_col =\"filename\",\n",
    "                                                  y_col=\"class\",\n",
    "                                                  target_size=Image_Size,\n",
    "                                                  batch_size=batch_siz,\n",
    "                                                  class_mode='binary',\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем Xception модель (веса) за исключением верхних выходных слоёв\n",
    "base_xcpt = Xception(include_top=False, weights = 'imagenet', pooling='avg', input_shape = (Image_Width,Image_Height,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добовляем наши верхние слои к Xception\n",
    "def new_top_layers(base):\n",
    "    x = base.output\n",
    "    x = Dense(512 , activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    pred = Dense(1, activation= 'sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs= base.input, outputs= pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем нашу модель, причем все веса основы (Xception) заморожены\n",
    "def assemble_model(model, base):\n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer= 'rmsprop', loss= 'binary_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = new_top_layers(base_xcpt)\n",
    "assemble_model(model, base_xcpt )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 36, 36, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 18, 18, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 18, 18, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 728)    186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 9, 9, 728)    2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 5, 5, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 5, 5, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,911,081\n",
      "Trainable params: 1,049,601\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Инициализируем EarlyStopping и сохраняем (после model.fit) лучшую модель на диск\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "checkpointer = ModelCheckpoint(filepath=\"D:\\\\Project_Georges\\\\top_weights.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pavel\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "250/250 [==============================] - 137s 511ms/step - loss: 0.7716 - accuracy: 0.6644 - val_loss: 0.4541 - val_accuracy: 0.7830\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45407, saving model to D:\\Project_Georges\\top_weights.hdf5\n",
      "Epoch 2/40\n",
      "250/250 [==============================] - 45s 181ms/step - loss: 0.4994 - accuracy: 0.7808 - val_loss: 0.4285 - val_accuracy: 0.8093\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45407 to 0.42853, saving model to D:\\Project_Georges\\top_weights.hdf5\n",
      "Epoch 3/40\n",
      "250/250 [==============================] - 44s 178ms/step - loss: 0.4685 - accuracy: 0.7913 - val_loss: 0.4324 - val_accuracy: 0.7935\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.42853\n",
      "Epoch 4/40\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.4338 - accuracy: 0.8040 - val_loss: 0.4144 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.42853 to 0.41441, saving model to D:\\Project_Georges\\top_weights.hdf5\n",
      "Epoch 5/40\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.4215 - accuracy: 0.8170 - val_loss: 0.4264 - val_accuracy: 0.8005\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41441\n",
      "Epoch 6/40\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.4103 - accuracy: 0.8193 - val_loss: 0.4334 - val_accuracy: 0.8040\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41441\n",
      "Epoch 7/40\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.3867 - accuracy: 0.8305 - val_loss: 0.4228 - val_accuracy: 0.8171\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41441\n",
      "Epoch 8/40\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 0.3641 - accuracy: 0.8480 - val_loss: 0.3916 - val_accuracy: 0.8346\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41441 to 0.39160, saving model to D:\\Project_Georges\\top_weights.hdf5\n",
      "Epoch 9/40\n",
      "250/250 [==============================] - 73s 292ms/step - loss: 0.3620 - accuracy: 0.8413 - val_loss: 0.4132 - val_accuracy: 0.8311\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.39160\n",
      "Epoch 10/40\n",
      "250/250 [==============================] - 45s 181ms/step - loss: 0.3628 - accuracy: 0.8579 - val_loss: 0.4040 - val_accuracy: 0.8294\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.39160\n",
      "Epoch 11/40\n",
      "250/250 [==============================] - 44s 178ms/step - loss: 0.3299 - accuracy: 0.8533 - val_loss: 0.3951 - val_accuracy: 0.8373\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.39160\n",
      "Epoch 12/40\n",
      "250/250 [==============================] - 44s 178ms/step - loss: 0.3219 - accuracy: 0.8631 - val_loss: 0.4091 - val_accuracy: 0.8355\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.39160\n",
      "Epoch 13/40\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.3206 - accuracy: 0.8704 - val_loss: 0.4477 - val_accuracy: 0.8093\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.39160\n",
      "Epoch 14/40\n",
      "250/250 [==============================] - 45s 178ms/step - loss: 0.3309 - accuracy: 0.8632 - val_loss: 0.4162 - val_accuracy: 0.8416\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.39160\n",
      "Epoch 15/40\n",
      "250/250 [==============================] - 46s 182ms/step - loss: 0.2994 - accuracy: 0.8733 - val_loss: 0.4061 - val_accuracy: 0.8399\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.39160\n",
      "Epoch 16/40\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 0.3029 - accuracy: 0.8658 - val_loss: 0.4159 - val_accuracy: 0.8346\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.39160\n",
      "Epoch 17/40\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.2943 - accuracy: 0.8788 - val_loss: 0.4796 - val_accuracy: 0.8136\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.39160\n",
      "Epoch 18/40\n",
      "250/250 [==============================] - 45s 178ms/step - loss: 0.2867 - accuracy: 0.8834 - val_loss: 0.4252 - val_accuracy: 0.8364\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.39160\n",
      "Epoch 19/40\n",
      "250/250 [==============================] - 44s 178ms/step - loss: 0.2830 - accuracy: 0.8818 - val_loss: 0.4447 - val_accuracy: 0.8434\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.39160\n",
      "Epoch 20/40\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.3096 - accuracy: 0.8803 - val_loss: 0.4501 - val_accuracy: 0.8443\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.39160\n",
      "Epoch 21/40\n",
      "250/250 [==============================] - 45s 178ms/step - loss: 0.2925 - accuracy: 0.8847 - val_loss: 0.4493 - val_accuracy: 0.8285\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.39160\n",
      "Epoch 22/40\n",
      "250/250 [==============================] - 44s 178ms/step - loss: 0.2574 - accuracy: 0.8918 - val_loss: 0.5184 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.39160\n",
      "Epoch 23/40\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.2979 - accuracy: 0.8820 - val_loss: 0.4589 - val_accuracy: 0.8320\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.39160\n",
      "Epoch 00023: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e38b3512b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, epochs=40, steps_per_epoch= np.ceil(train_generator.samples/ train_generator.batch_size), \n",
    "         validation_data=validation_generator, validation_steps=np.ceil(validation_generator.samples/ validation_generator.batch_size),\n",
    "         callbacks=[early_stop, checkpointer],\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pavel\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39159926772117615, 0.834645688533783]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем лучшую модель\n",
    "model = load_model(\"D:\\\\Project_Georges\\\\top_weights.hdf5\")\n",
    "model.evaluate_generator(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x0000012429227E80> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000124292274F0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F6163D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F616C70> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F616BE0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7BD070> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7BD8B0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7BD820> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7BD880> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7C0700> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7C0670> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7C0F40> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F7C50D0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001242F7C54C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7C5CD0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7C5DC0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7CA3A0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7CA340> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7CACD0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7CAE20> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7CADF0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7CEB20> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F7CEC70> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001242F7D3310> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7D38B0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7D39A0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7D3F40> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7D3EE0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7D78B0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7D7E80> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7D7DF0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7DC700> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F7DC850> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001242F7DCC40> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7E0490> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7E0580> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7E0B20> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7E0AC0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7E4490> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7E4A60> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7E49D0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7E4A30> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7E98B0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7E9820> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7E9880> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7EE280> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7EE820> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7EE7C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7EE7F0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7F2760> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7F26D0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7F2FA0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7F55B0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7F5520> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7F5DF0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7F5F40> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7FC520> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7FC4C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7FCE50> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7FCFA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7FCF70> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F801CA0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F801DF0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F801DC0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F804AF0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F804C40> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F809220> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F8091C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F809B50> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F809CA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F809C70> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F80F9D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F80FFA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F80FF10> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F812820> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F812970> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F812F10> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F812EB0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F816880> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F816E50> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F816DC0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F81B6D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F81BCA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F81BC10> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F81F520> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F81F670> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F81FC10> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F81FBB0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F823580> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F823B50> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F823AC0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F8293D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F8299A0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F829910> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F829970> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F82D370> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F82D910> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F82D8B0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F82D8E0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F963850> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F9637C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F963820> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F9666A0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F966610> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F966EE0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F96B070> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F96B610> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F96B5B0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F96BF40> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F96F550> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F96F4C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F96FD90> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F96FEE0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F96FEB0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F971BE0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F971D30> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F97A310> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F97A2B0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F97AC40> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F97AD90> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F97AD60> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F97FA90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F97FBE0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001242F983280> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F983820> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F983910> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F983DF0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F988640> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F988C10> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F988B80> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F98C490> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F98CA60> False\n",
      "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x000001242F98CB20> False\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001242F98CA30> True\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x000001242F98CE50> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001242F992280> True\n"
     ]
    }
   ],
   "source": [
    "# Проверяем какие слои заморожены\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция, которая размораживает верхние num_trainable слои\n",
    "def finetune(model, num_trainable):\n",
    "    for layer in model.layers[ : len(model.layers) - num_trainable]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[len(model.layers) - num_trainable : ]: \n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizers.SGD(lr=0.001, momentum=0.9),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размораживаем верхние 2 блока (блок 13 и 14) Xception (19 слоёв)\n",
    "finetune(model, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x0000012429227E80> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000124292274F0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F6163D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F616C70> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F616BE0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7BD070> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7BD8B0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7BD820> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7BD880> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7C0700> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7C0670> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7C0F40> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F7C50D0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001242F7C54C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7C5CD0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7C5DC0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7CA3A0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7CA340> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7CACD0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7CAE20> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7CADF0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7CEB20> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F7CEC70> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001242F7D3310> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7D38B0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7D39A0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7D3F40> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7D3EE0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7D78B0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7D7E80> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7D7DF0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7DC700> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F7DC850> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001242F7DCC40> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7E0490> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7E0580> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7E0B20> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7E0AC0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7E4490> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7E4A60> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7E49D0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7E4A30> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7E98B0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7E9820> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7E9880> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7EE280> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7EE820> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7EE7C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7EE7F0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7F2760> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7F26D0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7F2FA0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7F55B0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7F5520> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7F5DF0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F7F5F40> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7FC520> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7FC4C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F7FCE50> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F7FCFA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F7FCF70> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F801CA0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F801DF0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F801DC0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F804AF0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F804C40> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F809220> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F8091C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F809B50> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F809CA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F809C70> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F80F9D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F80FFA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F80FF10> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F812820> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F812970> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F812F10> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F812EB0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F816880> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F816E50> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F816DC0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F81B6D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F81BCA0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F81BC10> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F81F520> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F81F670> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F81FC10> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F81FBB0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F823580> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F823B50> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F823AC0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F8293D0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F8299A0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F829910> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F829970> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F82D370> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F82D910> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F82D8B0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F82D8E0> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F963850> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F9637C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F963820> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F9666A0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F966610> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F966EE0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F96B070> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F96B610> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F96B5B0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F96BF40> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F96F550> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F96F4C0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F96FD90> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F96FEE0> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F96FEB0> False\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F971BE0> False\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F971D30> False\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F97A310> False\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F97A2B0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F97AC40> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F97AD90> True\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F97AD60> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F97FA90> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000001242F97FBE0> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x000001242F983280> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F983820> True\n",
      "<tensorflow.python.keras.layers.merge.Add object at 0x000001242F983910> True\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F983DF0> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F988640> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F988C10> True\n",
      "<tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x000001242F988B80> True\n",
      "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000001242F98C490> True\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x000001242F98CA60> True\n",
      "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x000001242F98CB20> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001242F98CA30> True\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x000001242F98CE50> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x000001242F992280> True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer_1 = ModelCheckpoint(filepath='D:\\\\Project_Georges\\\\finetune_model.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pavel\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "250/250 [==============================] - 52s 193ms/step - loss: 0.4905 - accuracy: 0.7838 - val_loss: 0.3708 - val_accuracy: 0.8381\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37084, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.3736 - accuracy: 0.8327 - val_loss: 0.3469 - val_accuracy: 0.8469\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37084 to 0.34686, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.3221 - accuracy: 0.8546 - val_loss: 0.3573 - val_accuracy: 0.8539\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.34686\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.2996 - accuracy: 0.8721 - val_loss: 0.3381 - val_accuracy: 0.8574\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34686 to 0.33808, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.2910 - accuracy: 0.8720 - val_loss: 0.3306 - val_accuracy: 0.8574\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33808 to 0.33061, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 45s 181ms/step - loss: 0.2754 - accuracy: 0.8812 - val_loss: 0.3201 - val_accuracy: 0.8591\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.33061 to 0.32011, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.2694 - accuracy: 0.8786 - val_loss: 0.3377 - val_accuracy: 0.8591\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.32011\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 45s 181ms/step - loss: 0.2431 - accuracy: 0.8980 - val_loss: 0.3129 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.32011 to 0.31286, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 45s 181ms/step - loss: 0.2084 - accuracy: 0.9196 - val_loss: 0.3100 - val_accuracy: 0.8766\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.31286 to 0.30995, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.2080 - accuracy: 0.9133 - val_loss: 0.3026 - val_accuracy: 0.8801\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30995 to 0.30264, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.2075 - accuracy: 0.9171 - val_loss: 0.3167 - val_accuracy: 0.8749\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.30264\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1951 - accuracy: 0.9221 - val_loss: 0.2919 - val_accuracy: 0.8819\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.30264 to 0.29194, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.1898 - accuracy: 0.9264 - val_loss: 0.2904 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29194 to 0.29043, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.2220 - accuracy: 0.9108 - val_loss: 0.2993 - val_accuracy: 0.8836\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.29043\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.2062 - accuracy: 0.9215 - val_loss: 0.2991 - val_accuracy: 0.8775\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.29043\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.1707 - accuracy: 0.9311 - val_loss: 0.3101 - val_accuracy: 0.8749\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.29043\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.1525 - accuracy: 0.9388 - val_loss: 0.3330 - val_accuracy: 0.8688\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.29043\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.1662 - accuracy: 0.9293 - val_loss: 0.3094 - val_accuracy: 0.8845\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.29043\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.1625 - accuracy: 0.9367 - val_loss: 0.2953 - val_accuracy: 0.8828\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.29043\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1489 - accuracy: 0.9408 - val_loss: 0.2992 - val_accuracy: 0.8941\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.29043\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1404 - accuracy: 0.9460 - val_loss: 0.3081 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.29043\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.1473 - accuracy: 0.9410 - val_loss: 0.3080 - val_accuracy: 0.8906\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.29043\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1466 - accuracy: 0.9428 - val_loss: 0.3117 - val_accuracy: 0.8801\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.29043\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1316 - accuracy: 0.9454 - val_loss: 0.3030 - val_accuracy: 0.8976\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.29043\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1125 - accuracy: 0.9554 - val_loss: 0.3074 - val_accuracy: 0.8863\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.29043\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1284 - accuracy: 0.9475 - val_loss: 0.2986 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.29043\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1255 - accuracy: 0.9510 - val_loss: 0.3085 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.29043\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1221 - accuracy: 0.9477 - val_loss: 0.2875 - val_accuracy: 0.9011\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.29043 to 0.28753, saving model to D:\\Project_Georges\\finetune_model.hdf5\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.1241 - accuracy: 0.9491 - val_loss: 0.3082 - val_accuracy: 0.8915\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.28753\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.1125 - accuracy: 0.9597 - val_loss: 0.3051 - val_accuracy: 0.8906\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.28753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12430efeb50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Повторно обучаем нашу модель с двумя размороженными блоками (13 и 14)\n",
    "model.fit_generator(train_generator, epochs=30, steps_per_epoch= np.ceil(train_generator.samples/ train_generator.batch_size), \n",
    "         validation_data=validation_generator, validation_steps=np.ceil(validation_generator.samples/ validation_generator.batch_size),\n",
    "         callbacks=[early_stop, checkpointer_1],\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pavel\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2875267267227173, 0.9011373519897461]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(\"D:\\\\Project_Georges\\\\finetune_model.hdf5\")\n",
    "model.evaluate_generator(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions (test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pavel\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       236\n",
      "           1       0.91      0.92      0.91       324\n",
      "\n",
      "    accuracy                           0.90       560\n",
      "   macro avg       0.90      0.89      0.90       560\n",
      "weighted avg       0.90      0.90      0.90       560\n",
      "\n",
      "[[206  30]\n",
      " [ 27 297]]\n",
      "{'georges': 0, 'non_georges': 1}\n"
     ]
    }
   ],
   "source": [
    "results = model.predict_generator(test_generator, steps=np.ceil(test_generator.samples/ test_generator.batch_size))\n",
    "print(classification_report(test_generator.classes, np.round(results[:,0])))\n",
    "print(confusion_matrix(y_true= test_generator.classes, y_pred= np.round(results[:,0])))\n",
    "print(test_generator.class_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
